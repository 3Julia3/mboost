
R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> require("mboost")
Loading required package: mboost
Loading required package: parallel
Loading required package: stabs
This is mboost 2.8-0. See 'package?mboost' and 'news(package  = "mboost")'
for a complete list of changes.

> 
> set.seed(1907)
> 
> ### check confidence intervals
> data("bodyfat", package = "TH.data")
> bodyfat$ID <- factor(sample(1:5, size = nrow(bodyfat), replace = TRUE))
> glm <- glmboost(DEXfat ~ ., data = bodyfat)
> gam <- gamboost(DEXfat ~ ., data = bodyfat)
Warning message:
In bbs(as.data.frame(list(...)), df = dfbase) :
  cannot compute 'bbs' for non-numeric variables; used 'bols' instead.
> 
> refit <- glm$update(weights = model.weights(glm), risk = "inbag")
> stopifnot(all.equal(coef(refit), coef(glm)))
> 
> glm[200]

	 Generalized Linear Models Fitted via Gradient Boosting

Call:
glmboost.formula(formula = DEXfat ~ ., data = bodyfat)


	 Squared Error (Regression) 

Loss function: (y - f)^2 
 

Number of boosting iterations: mstop = 200 
Step size:  0.1 
Offset:  30.78282 

Coefficients: 
  (Intercept)           age     waistcirc       hipcirc  elbowbreadth 
-98.267586175   0.007743431   0.189304614   0.365744326  -0.118303213 
  kneebreadth      anthro3a      anthro3b      anthro3c           ID2 
  1.613621424   3.326860270   3.458883502   0.514108117  -0.833010169 
          ID3           ID4           ID5 
 -0.925934420  -1.979498322  -1.771987847 
attr(,"offset")
[1] 30.78282

> confint.glm <- confint(glm, B = 100, B.mstop = 2)
There were 50 or more warnings (use warnings() to see the first 50)
> confint.glm
	Bootstrap Confidence Intervals
                     2.5%        97.5%
(Intercept)  -78.05959532 -48.53585992
age           -0.01006118   0.04787764
waistcirc      0.08009208   0.29340444
hipcirc        0.20586965   0.52028270
elbowbreadth  -1.28224120   1.00828926
kneebreadth    0.03202871   3.13241905
anthro3a       0.00000000   7.16424617
anthro3b       0.00000000   6.34765206
anthro3c       0.00000000   4.03626864
anthro4        0.00000000   3.96809690
ID2           -1.91672133   1.16889159
ID3           -2.03416976   0.37211182
ID4           -3.33076662   0.00000000
ID5           -3.22332317   0.33953241
> 
> confint.gam <- confint(gam, B = 100, B.mstop = 1)
Start computing bootstrap confidence intervals... 
B = 1B = 2B = 3B = 4B = 5B = 6B = 7B = 8B = 9B = 10B = 11B = 12B = 13B = 14B = 15B = 16B = 17B = 18B = 19B = 20B = 21B = 22B = 23B = 24B = 25B = 26B = 27B = 28B = 29B = 30B = 31B = 32B = 33B = 34B = 35B = 36B = 37B = 38B = 39B = 40B = 41B = 42B = 43B = 44B = 45B = 46B = 47B = 48B = 49B = 50B = 51B = 52B = 53B = 54B = 55B = 56B = 57B = 58B = 59B = 60B = 61B = 62B = 63B = 64B = 65B = 66B = 67B = 68B = 69B = 70B = 71B = 72B = 73B = 74B = 75B = 76B = 77B = 78B = 79B = 80B = 81B = 82B = 83B = 84B = 85B = 86B = 87B = 88B = 89B = 90B = 91B = 92B = 93B = 94B = 95B = 96B = 97B = 98B = 99B = 100
There were 50 or more warnings (use warnings() to see the first 50)
> plot(confint.gam, which = 1)
> plot(confint.gam, which = 2)
> plot(confint.gam, which = 3)
> 
> 
> ### check cvrisk (it should run even if a fold leads to an error)
> folds <- cv(model.weights(glm), type = "kfold")
> 
> folds[1, 1] <- NA
> cvrisk(glm, folds = folds, papply = lapply)

	 Cross-validated Squared Error (Regression) 
	 glmboost.formula(formula = DEXfat ~ ., data = bodyfat) 

        0         1         2         3         4         5         6         7 
124.46673 106.00499  90.17077  77.45808  68.00035  59.86496  52.03966  46.42353 
        8         9        10        11        12        13        14        15 
 41.08156  36.81017  33.19998  30.42449  28.19571  25.90495  24.38864  22.80355 
       16        17        18        19        20        21        22        23 
 21.46370  20.40589  19.51735  18.60402  17.88003  17.31299  16.65787  16.31249 
       24        25        26        27        28        29        30        31 
 15.97345  15.66844  15.33807  14.97592  14.85146  14.60617  14.48172  14.42573 
       32        33        34        35        36        37        38        39 
 14.29366  14.27159  14.26389  14.24245  14.15062  14.20792  14.16730  14.18003 
       40        41        42        43        44        45        46        47 
 14.19040  14.17120  14.11303  14.08009  14.09280  14.01863  13.99513  13.99740 
       48        49        50        51        52        53        54        55 
 13.96282  13.95913  13.87333  13.91098  13.88561  13.86682  13.78991  13.83158 
       56        57        58        59        60        61        62        63 
 13.79465  13.78442  13.79694  13.80771  13.75575  13.71411  13.72570  13.78751 
       64        65        66        67        68        69        70        71 
 13.73471  13.70685  13.68803  13.72281  13.74093  13.67950  13.67998  13.72083 
       72        73        74        75        76        77        78        79 
 13.70507  13.67729  13.64560  13.69617  13.69006  13.65733  13.63958  13.67278 
       80        81        82        83        84        85        86        87 
 13.69696  13.70011  13.68231  13.64572  13.67049  13.67503  13.68405  13.70846 
       88        89        90        91        92        93        94        95 
 13.68897  13.67369  13.68764  13.68337  13.70392  13.68774  13.67618  13.69178 
       96        97        98        99       100       101       102       103 
 13.70229  13.72479  13.71284  13.66857  13.68758  13.67048  13.68822  13.66237 
      104       105       106       107       108       109       110       111 
 13.68622  13.67095  13.66825  13.64039  13.64424  13.67539  13.65819  13.66007 
      112       113       114       115       116       117       118       119 
 13.64094  13.65447  13.68132  13.67161  13.66099  13.68132  13.68399  13.69484 
      120       121       122       123       124       125       126       127 
 13.69498  13.67292  13.66345  13.65420  13.65801  13.68643  13.66948  13.66337 
      128       129       130       131       132       133       134       135 
 13.65994  13.69205  13.67853  13.65732  13.64885  13.67105  13.66069  13.67608 
      136       137       138       139       140       141       142       143 
 13.65987  13.64977  13.64360  13.66109  13.65929  13.65021  13.64071  13.65027 
      144       145       146       147       148       149       150       151 
 13.64815  13.65158  13.64272  13.67734  13.66481  13.65553  13.64250  13.64102 
      152       153       154       155       156       157       158       159 
 13.63810  13.64638  13.64039  13.63139  13.62446  13.62794  13.65381  13.65694 
      160       161       162       163       164       165       166       167 
 13.64226  13.62164  13.63214  13.64935  13.65412  13.64246  13.62517  13.64971 
      168       169       170       171       172       173       174       175 
 13.65127  13.64116  13.63704  13.64646  13.65512  13.65174  13.63624  13.63289 
      176       177       178       179       180       181       182       183 
 13.64397  13.65910  13.63746  13.63149  13.64487  13.65800  13.64148  13.63098 
      184       185       186       187       188       189       190       191 
 13.63562  13.65142  13.63307  13.63966  13.62798  13.65124  13.63338  13.64590 
      192       193       194       195       196       197       198       199 
 13.64191  13.63820  13.64755  13.63766  13.64169  13.63961  13.63368  13.64132 
      200 
 13.64130 

	 Optimal number of boosting iterations: 161 
Warning message:
In cvrisk.mboost(glm, folds = folds, papply = lapply) :
  1 fold(s) encountered an error. Results are based on 9 folds only.
Original error message(s):
Error in if (max(abs(w - floor(w))) < sqrt(.Machine$double.eps)) return(w) : 
  missing value where TRUE/FALSE needed

> cvrisk(glm, folds = folds, papply = mclapply)

	 Cross-validated Squared Error (Regression) 
	 glmboost.formula(formula = DEXfat ~ ., data = bodyfat) 

        0         1         2         3         4         5         6         7 
124.46673 106.00499  90.17077  77.45808  68.00035  59.86496  52.03966  46.42353 
        8         9        10        11        12        13        14        15 
 41.08156  36.81017  33.19998  30.42449  28.19571  25.90495  24.38864  22.80355 
       16        17        18        19        20        21        22        23 
 21.46370  20.40589  19.51735  18.60402  17.88003  17.31299  16.65787  16.31249 
       24        25        26        27        28        29        30        31 
 15.97345  15.66844  15.33807  14.97592  14.85146  14.60617  14.48172  14.42573 
       32        33        34        35        36        37        38        39 
 14.29366  14.27159  14.26389  14.24245  14.15062  14.20792  14.16730  14.18003 
       40        41        42        43        44        45        46        47 
 14.19040  14.17120  14.11303  14.08009  14.09280  14.01863  13.99513  13.99740 
       48        49        50        51        52        53        54        55 
 13.96282  13.95913  13.87333  13.91098  13.88561  13.86682  13.78991  13.83158 
       56        57        58        59        60        61        62        63 
 13.79465  13.78442  13.79694  13.80771  13.75575  13.71411  13.72570  13.78751 
       64        65        66        67        68        69        70        71 
 13.73471  13.70685  13.68803  13.72281  13.74093  13.67950  13.67998  13.72083 
       72        73        74        75        76        77        78        79 
 13.70507  13.67729  13.64560  13.69617  13.69006  13.65733  13.63958  13.67278 
       80        81        82        83        84        85        86        87 
 13.69696  13.70011  13.68231  13.64572  13.67049  13.67503  13.68405  13.70846 
       88        89        90        91        92        93        94        95 
 13.68897  13.67369  13.68764  13.68337  13.70392  13.68774  13.67618  13.69178 
       96        97        98        99       100       101       102       103 
 13.70229  13.72479  13.71284  13.66857  13.68758  13.67048  13.68822  13.66237 
      104       105       106       107       108       109       110       111 
 13.68622  13.67095  13.66825  13.64039  13.64424  13.67539  13.65819  13.66007 
      112       113       114       115       116       117       118       119 
 13.64094  13.65447  13.68132  13.67161  13.66099  13.68132  13.68399  13.69484 
      120       121       122       123       124       125       126       127 
 13.69498  13.67292  13.66345  13.65420  13.65801  13.68643  13.66948  13.66337 
      128       129       130       131       132       133       134       135 
 13.65994  13.69205  13.67853  13.65732  13.64885  13.67105  13.66069  13.67608 
      136       137       138       139       140       141       142       143 
 13.65987  13.64977  13.64360  13.66109  13.65929  13.65021  13.64071  13.65027 
      144       145       146       147       148       149       150       151 
 13.64815  13.65158  13.64272  13.67734  13.66481  13.65553  13.64250  13.64102 
      152       153       154       155       156       157       158       159 
 13.63810  13.64638  13.64039  13.63139  13.62446  13.62794  13.65381  13.65694 
      160       161       162       163       164       165       166       167 
 13.64226  13.62164  13.63214  13.64935  13.65412  13.64246  13.62517  13.64971 
      168       169       170       171       172       173       174       175 
 13.65127  13.64116  13.63704  13.64646  13.65512  13.65174  13.63624  13.63289 
      176       177       178       179       180       181       182       183 
 13.64397  13.65910  13.63746  13.63149  13.64487  13.65800  13.64148  13.63098 
      184       185       186       187       188       189       190       191 
 13.63562  13.65142  13.63307  13.63966  13.62798  13.65124  13.63338  13.64590 
      192       193       194       195       196       197       198       199 
 13.64191  13.63820  13.64755  13.63766  13.64169  13.63961  13.63368  13.64132 
      200 
 13.64130 

	 Optimal number of boosting iterations: 161 
Warning message:
In cvrisk.mboost(glm, folds = folds, papply = mclapply) :
  1 fold(s) encountered an error. Results are based on 9 folds only.
Original error message(s):
Error in if (max(abs(w - floor(w))) < sqrt(.Machine$double.eps)) return(w) : 
  missing value where TRUE/FALSE needed

> 
> ## test if cvrisk starts at 0 and provides a sensible model
> 
> data <- data.frame(y = rnorm(100), x1 = rnorm(100), x2 = rnorm(100), x3 = rnorm(100))
> glm <- glmboost(y ~ ., data = data)
> gam <- gamboost(y ~ ., data = data)
> 
> cvr.glm <- cvrisk(glm)
> cvr.gam <- cvrisk(gam)
> stopifnot(mstop(cvr.glm) == 0)
> stopifnot(mstop(cvr.gam) == 0)
> 
> proc.time()
   user  system elapsed 
  28.18    0.12   28.36 
